{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics tqdm --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 15:48:37.211207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-24 15:48:37.820340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "seq_len = 70\n",
    "batch_size = 25\n",
    "min_freq = 0\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "max_lr_dec = 3\n",
    "lr_dec = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_trainable_params(model):\n",
    "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
    "  return nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet --continue https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
    "!unzip -q wikitext-2-v1.zip\n",
    "!cd wikitext-2 && mv wiki.train.tokens train.txt\n",
    "!cd wikitext-2 && mv wiki.valid.tokens valid.txt\n",
    "!cd wikitext-2 && mv wiki.test.tokens test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"moses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        dataset = file.read()\n",
    "    return dataset\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    tokens = []\n",
    "    for line in dataset.split('\\n'):\n",
    "        line_tokens = tokenizer(line.strip())\n",
    "        tokens.extend(line_tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Tokens:  2222445\n",
      "Valid Tokens:  243937\n",
      "Test Tokens:  279249\n",
      "Total number of tokens: 2745631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = load_dataset(\"../wikitext-2/train.txt\")\n",
    "valid_dataset = load_dataset(\"../wikitext-2/valid.txt\")\n",
    "test_dataset = load_dataset(\"../wikitext-2/test.txt\")\n",
    "\n",
    "train_tokens = tokenize_dataset(train_dataset)\n",
    "valid_tokens = tokenize_dataset(valid_dataset)\n",
    "test_tokens = tokenize_dataset(test_dataset)\n",
    "\n",
    "all_tokens = train_tokens + valid_tokens + test_tokens\n",
    "print(\"Train Tokens: \" , len(train_tokens))\n",
    "print(\"Valid Tokens: \" , len(valid_tokens))\n",
    "print(\"Test Tokens: \" , len(test_tokens))\n",
    "print(\"Total number of tokens:\", len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 33264\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = [train_tokens] \n",
    "\n",
    "special_tokens = ['<pad>', '<unk>', '<bos>', '<eos>']\n",
    "\n",
    "vocab = build_vocab_from_iterator(tokenized_datasets, specials=special_tokens , min_freq=min_freq)\n",
    "\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "vocab_itos = vocab.get_itos()\n",
    "\n",
    "torch.save(vocab, f\"./train_vocab_moses_{min_freq}.voc\")\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wikitext2Dataset(Dataset):\n",
    "  def __init__(self, tokens, seq_len):\n",
    "    self.tokens = tokens\n",
    "    self.seq_len = seq_len\n",
    "  def __len__(self):\n",
    "    return  len(self.tokens) // self.seq_len\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    start_idx = idx * self.seq_len\n",
    "    end_idx = start_idx + self.seq_len\n",
    "    input = self.tokens[start_idx:end_idx]\n",
    "    target = self.tokens[start_idx+1:end_idx+1]\n",
    "    return torch.tensor(input), torch.tensor(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_voc = vocab(train_tokens)\n",
    "valid_tokens_voc = vocab(valid_tokens)\n",
    "test_tokens_voc = vocab(test_tokens)\n",
    "\n",
    "# Datasets\n",
    "train_dataset = Wikitext2Dataset(train_tokens_voc, seq_len)\n",
    "valid_dataset = Wikitext2Dataset(valid_tokens_voc, seq_len)\n",
    "test_dataset = Wikitext2Dataset(test_tokens_voc, seq_len)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset , batch_size )\n",
    "valid_loader = DataLoader(valid_dataset , batch_size )\n",
    "test_loader = DataLoader(test_dataset , batch_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H_LSTM(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    \n",
    "    #Embedding Layer\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.dropout_em = nn.Dropout(0.1)\n",
    "    \n",
    "    # Layer 1\n",
    "    self.rnn1 = nn.LSTM(input_size=embedding_dim,\n",
    "                      hidden_size=hidden_dim,\n",
    "                      num_layers=num_layers,\n",
    "                      bidirectional=False,\n",
    "                      batch_first=True)\n",
    "    self.dropout1 = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    # Layer 2\n",
    "    self.rnn2 = nn.LSTM(input_size=hidden_dim,\n",
    "                      hidden_size=hidden_dim,\n",
    "                      num_layers=num_layers,\n",
    "                      bidirectional=False,\n",
    "                      batch_first=True)\n",
    "    self.dropout2 = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    # Layer 3\n",
    "    self.rnn3 = nn.LSTM(input_size=hidden_dim,\n",
    "                      hidden_size=hidden_dim,\n",
    "                      num_layers=1,\n",
    "                      bidirectional=False,\n",
    "                      batch_first=True)\n",
    "    self.dropout3 = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    self.fc = nn.Linear(hidden_dim,vocab_size,bias=True)\n",
    "\n",
    "  def forward(self, src):\n",
    "    embedding = self.dropout_em( self.embedding(src) )\n",
    "    \n",
    "    output, (h,c) = self.rnn1(embedding)\n",
    "    output = self.dropout1(output)\n",
    "    \n",
    "    output, (h,c) = self.rnn2(output,(c,h))\n",
    "    output = self.dropout2(output)\n",
    "    \n",
    "    output, (h,c) = self.rnn3(output,(c,h))\n",
    "    output = self.dropout3(output)\n",
    "    \n",
    "    output = self.fc(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, perp , epoch=1):\n",
    "  \n",
    "  global seq_len\n",
    "  global batch_size\n",
    "  \n",
    "  model.train()\n",
    "  loss_train = AverageMeter()\n",
    "  perplexity_train = AverageMeter()\n",
    "    \n",
    "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
    "    for inputs, targets in tepoch:\n",
    "\n",
    "      tepoch.set_description(f'Epoch {epoch}')\n",
    "\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      batch_size, seq_len, vocab_size = outputs.size()\n",
    "      outputs = outputs.view(batch_size * seq_len, vocab_size)\n",
    "      targets = targets.view(-1)\n",
    "      \n",
    "      loss = loss_fn(outputs, targets)\n",
    "      \n",
    "      loss.backward()\n",
    "      \n",
    "      perplexity = perp(outputs.view(batch_size, seq_len, vocab_size), targets.view(batch_size, seq_len))\n",
    "      \n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss_train.update(loss.item(), n=len(targets))\n",
    "      perplexity_train.update(perplexity.item(), n=len(targets))\n",
    "\n",
    "      tepoch.set_postfix(loss=loss_train.avg, perplexity = perplexity_train.avg )\n",
    "      \n",
    "      del inputs\n",
    "      del targets\n",
    "      del outputs\n",
    "\n",
    "  return model, loss_train.avg, perplexity_train.avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, loss_fn , perp ):\n",
    "  \n",
    "  global seq_len\n",
    "  global batch_size\n",
    "  \n",
    "  model.eval()\n",
    "  loss_eval = AverageMeter()\n",
    "  perplexity_eval = AverageMeter()\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    for inputs, targets in test_loader:\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      \n",
    "      batch_size, seq_len, vocab_size = outputs.size()\n",
    "      outputs = outputs.view(batch_size * seq_len, vocab_size)\n",
    "      targets = targets.view(-1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      \n",
    "      perplexity = perp(outputs.view(batch_size, seq_len, vocab_size), targets.view(batch_size, seq_len))\n",
    "\n",
    "      loss_eval.update(loss.item(), n=len(targets))\n",
    "      perplexity_eval.update(perplexity.item(), n=len(targets))\n",
    "      \n",
    "      del inputs\n",
    "      del targets\n",
    "      del outputs\n",
    "\n",
    "  return loss_eval.avg,perplexity_eval.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 39.309264\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "H_LSTM(\n",
       "  (embedding): Embedding(33264, 500)\n",
       "  (dropout_em): Dropout(p=0.1, inplace=False)\n",
       "  (rnn1): LSTM(500, 500, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (rnn2): LSTM(500, 500, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.25, inplace=False)\n",
       "  (rnn3): LSTM(500, 500, batch_first=True)\n",
       "  (dropout3): Dropout(p=0.25, inplace=False)\n",
       "  (fc): Linear(in_features=500, out_features=33264, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 500\n",
    "hidden_dim = 500\n",
    "num_layers = 1\n",
    "dropout_rate = 0.25\n",
    "\n",
    "model = H_LSTM( vocab_size, embedding_dim=embedding_dim, hidden_dim=hidden_dim , num_layers=num_layers, dropout_rate= dropout_rate )\n",
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "\n",
    "per_train_hist = []\n",
    "per_valid_hist = []\n",
    "\n",
    "lr_train_hist = []\n",
    "\n",
    "best_perplexity_valid = torch.inf\n",
    "epoch_counter = 0\n",
    "print(f\"Trainable Parameters: {num_trainable_params(model)}\\n\")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "wd = 1e-5\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "perp = Perplexity().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1270/1270 [01:52<00:00, 11.28batch/s, loss=6.3, perplexity=915]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 5.303 Perplexity= 210.2, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1270/1270 [01:52<00:00, 11.31batch/s, loss=5.64, perplexity=289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 5.029 Perplexity= 159.2, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1270/1270 [01:53<00:00, 11.16batch/s, loss=5.39, perplexity=225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.884 Perplexity= 137.4, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1270/1270 [01:53<00:00, 11.18batch/s, loss=5.22, perplexity=190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.796 Perplexity= 125.9, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1270/1270 [01:53<00:00, 11.23batch/s, loss=5.09, perplexity=167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.727 Perplexity= 117.6, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1270/1270 [01:52<00:00, 11.34batch/s, loss=4.98, perplexity=150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.662 Perplexity= 110.2, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1270/1270 [01:53<00:00, 11.21batch/s, loss=4.89, perplexity=138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.621 Perplexity= 105.8, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1270/1270 [01:53<00:00, 11.19batch/s, loss=4.81, perplexity=127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.593 Perplexity= 103.0, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1270/1270 [01:53<00:00, 11.15batch/s, loss=4.74, perplexity=119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.561 Perplexity= 99.77, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1270/1270 [01:53<00:00, 11.16batch/s, loss=4.67, perplexity=111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.548 Perplexity= 98.62, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1270/1270 [01:52<00:00, 11.25batch/s, loss=4.62, perplexity=105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.532 Perplexity= 97.07, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1270/1270 [01:51<00:00, 11.38batch/s, loss=4.57, perplexity=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.529 Perplexity= 96.85, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1270/1270 [01:52<00:00, 11.27batch/s, loss=4.52, perplexity=95.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.516 Perplexity= 95.74, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1270/1270 [01:53<00:00, 11.16batch/s, loss=4.48, perplexity=91.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.507 Perplexity= 94.9, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1270/1270 [01:54<00:00, 11.12batch/s, loss=4.44, perplexity=88.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.498 Perplexity= 94.07, LR = 0.5\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1270/1270 [01:52<00:00, 11.25batch/s, loss=4.41, perplexity=85.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.501 Perplexity= 94.42, LR = 0.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1270/1270 [01:52<00:00, 11.33batch/s, loss=4.31, perplexity=78.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.418 Perplexity= 86.67, LR = 0.25\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1270/1270 [01:52<00:00, 11.24batch/s, loss=4.26, perplexity=74]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.406 Perplexity= 85.71, LR = 0.25\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1270/1270 [01:54<00:00, 11.12batch/s, loss=4.23, perplexity=71.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.406 Perplexity= 85.74, LR = 0.25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1270/1270 [01:54<00:00, 11.12batch/s, loss=4.2, perplexity=69.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.361 Perplexity= 81.96, LR = 0.125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1270/1270 [01:52<00:00, 11.27batch/s, loss=4.16, perplexity=67]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.341 Perplexity= 80.23, LR = 0.125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1270/1270 [01:52<00:00, 11.31batch/s, loss=4.14, perplexity=65.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.341 Perplexity= 80.34, LR = 0.125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1270/1270 [01:53<00:00, 11.20batch/s, loss=4.13, perplexity=64.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.301 Perplexity= 77.09, LR = 0.0625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1270/1270 [01:54<00:00, 11.11batch/s, loss=4.11, perplexity=63.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.297 Perplexity= 76.74, LR = 0.0625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1270/1270 [01:53<00:00, 11.14batch/s, loss=4.09, perplexity=62.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.295 Perplexity= 76.59, LR = 0.0625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1270/1270 [01:47<00:00, 11.80batch/s, loss=4.08, perplexity=62]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.287 Perplexity= 76.01, LR = 0.0625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1270/1270 [01:51<00:00, 11.34batch/s, loss=4.07, perplexity=61.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.288 Perplexity= 76.11, LR = 0.0625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1270/1270 [01:54<00:00, 11.12batch/s, loss=4.07, perplexity=61.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.26 Perplexity= 74.01, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1270/1270 [01:53<00:00, 11.17batch/s, loss=4.06, perplexity=60.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.258 Perplexity= 73.83, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1270/1270 [01:52<00:00, 11.29batch/s, loss=4.05, perplexity=60.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.256 Perplexity= 73.7, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1270/1270 [01:52<00:00, 11.26batch/s, loss=4.05, perplexity=59.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.255 Perplexity= 73.58, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 1270/1270 [01:53<00:00, 11.15batch/s, loss=4.04, perplexity=59.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.254 Perplexity= 73.57, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 1270/1270 [01:53<00:00, 11.18batch/s, loss=4.03, perplexity=58.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.254 Perplexity= 73.52, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1270/1270 [01:52<00:00, 11.27batch/s, loss=4.03, perplexity=58.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.251 Perplexity= 73.32, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1270/1270 [01:52<00:00, 11.29batch/s, loss=4.02, perplexity=58.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.25 Perplexity= 73.26, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 1270/1270 [01:53<00:00, 11.17batch/s, loss=4.01, perplexity=57.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.249 Perplexity= 73.19, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 1270/1270 [01:53<00:00, 11.15batch/s, loss=4.01, perplexity=57.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.247 Perplexity= 73.07, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 1270/1270 [01:52<00:00, 11.25batch/s, loss=4, perplexity=57.2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.247 Perplexity= 73.03, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 1270/1270 [01:52<00:00, 11.29batch/s, loss=4, perplexity=56.9]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.246 Perplexity= 72.96, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1270/1270 [01:53<00:00, 11.17batch/s, loss=3.99, perplexity=56.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.242 Perplexity= 72.71, LR = 0.03125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 1270/1270 [01:54<00:00, 11.13batch/s, loss=3.99, perplexity=56.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.244 Perplexity= 72.83, LR = 0.03125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 1270/1270 [01:53<00:00, 11.20batch/s, loss=3.99, perplexity=56.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.23 Perplexity= 71.8, LR = 0.015625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 1270/1270 [01:52<00:00, 11.31batch/s, loss=3.98, perplexity=56.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.229 Perplexity= 71.72, LR = 0.015625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 1270/1270 [01:52<00:00, 11.26batch/s, loss=3.98, perplexity=56]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.226 Perplexity= 71.53, LR = 0.015625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1270/1270 [01:53<00:00, 11.15batch/s, loss=3.98, perplexity=55.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.224 Perplexity= 71.38, LR = 0.015625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 1270/1270 [01:54<00:00, 11.13batch/s, loss=3.98, perplexity=55.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.224 Perplexity= 71.38, LR = 0.015625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1270/1270 [01:52<00:00, 11.26batch/s, loss=3.97, perplexity=55.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.225 Perplexity= 71.47, LR = 0.015625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1270/1270 [01:52<00:00, 11.31batch/s, loss=3.98, perplexity=55.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.218 Perplexity= 70.92, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 1270/1270 [01:53<00:00, 11.23batch/s, loss=3.98, perplexity=55.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.216 Perplexity= 70.79, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1270/1270 [01:54<00:00, 11.12batch/s, loss=3.98, perplexity=55.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.213 Perplexity= 70.61, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 1270/1270 [01:53<00:00, 11.16batch/s, loss=3.97, perplexity=55.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.212 Perplexity= 70.49, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 1270/1270 [01:52<00:00, 11.32batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.211 Perplexity= 70.47, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 1270/1270 [01:52<00:00, 11.30batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.21 Perplexity= 70.37, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 1270/1270 [01:53<00:00, 11.17batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.209 Perplexity= 70.29, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 1270/1270 [01:54<00:00, 11.13batch/s, loss=3.97, perplexity=55.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.208 Perplexity= 70.23, LR = 0.0078125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 1270/1270 [01:53<00:00, 11.21batch/s, loss=3.97, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.208 Perplexity= 70.25, LR = 0.0078125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 1270/1270 [01:51<00:00, 11.35batch/s, loss=3.97, perplexity=55.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.203 Perplexity= 69.87, LR = 0.00390625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 1270/1270 [01:52<00:00, 11.25batch/s, loss=3.97, perplexity=55.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.202 Perplexity= 69.78, LR = 0.00390625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 1270/1270 [01:54<00:00, 11.14batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.201 Perplexity= 69.76, LR = 0.00390625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1270/1270 [01:54<00:00, 11.13batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.2 Perplexity= 69.7, LR = 0.00390625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 1270/1270 [01:52<00:00, 11.34batch/s, loss=3.97, perplexity=55.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.201 Perplexity= 69.72, LR = 0.00390625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 1270/1270 [01:51<00:00, 11.35batch/s, loss=3.97, perplexity=55.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.196 Perplexity= 69.38, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 1270/1270 [01:52<00:00, 11.33batch/s, loss=3.97, perplexity=55.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.195 Perplexity= 69.35, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 1270/1270 [01:43<00:00, 12.32batch/s, loss=3.97, perplexity=55.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.195 Perplexity= 69.29, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.194 Perplexity= 69.28, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.194 Perplexity= 69.24, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.193 Perplexity= 69.2, LR = 0.001953125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.193 Perplexity= 69.21, LR = 0.001953125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.97, perplexity=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.192 Perplexity= 69.07, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.191 Perplexity= 69.03, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.191 Perplexity= 69.02, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.191 Perplexity= 69.02, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.97, perplexity=55.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 69.0, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.99, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.97, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.97, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.97, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.96, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.94, LR = 0.0009765625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 1270/1270 [01:43<00:00, 12.32batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.19 Perplexity= 68.96, LR = 0.0009765625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.189 Perplexity= 68.91, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.189 Perplexity= 68.89, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.189 Perplexity= 68.88, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 1270/1270 [01:43<00:00, 12.32batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.189 Perplexity= 68.86, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.86, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.85, LR = 0.00048828125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.86, LR = 0.00048828125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.83, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.82, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.82, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.81, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.81, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.8, LR = 0.000244140625\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.188 Perplexity= 68.81, LR = 0.000244140625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.78, LR = 0.0001220703125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.78, LR = 0.0001220703125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.78, LR = 0.0001220703125\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.78, LR = 0.0001220703125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.77, LR = 6.103515625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.77, LR = 6.103515625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.77, LR = 6.103515625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 1270/1270 [01:43<00:00, 12.32batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 6.103515625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|██████████| 1270/1270 [01:43<00:00, 12.28batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 6.103515625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 6.103515625e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 3.0517578125e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.76, LR = 1.52587890625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 1.52587890625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 1.52587890625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 1.52587890625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 1.52587890625e-05\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 1.52587890625e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116: 100%|██████████| 1270/1270 [01:43<00:00, 12.29batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 7.62939453125e-06\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 7.62939453125e-06\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118: 100%|██████████| 1270/1270 [01:43<00:00, 12.28batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 7.62939453125e-06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1270/1270 [01:43<00:00, 12.30batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 3.814697265625e-06\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120: 100%|██████████| 1270/1270 [01:43<00:00, 12.31batch/s, loss=3.96, perplexity=54.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 3.814697265625e-06\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|██████████| 1270/1270 [01:44<00:00, 12.14batch/s, loss=3.96, perplexity=54.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 4.187 Perplexity= 68.75, LR = 3.814697265625e-06\n",
      "Model Saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122:   8%|▊         | 102/1270 [00:09<01:46, 11.01batch/s, loss=4.01, perplexity=57.3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(num_epochs):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Train</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>model, loss_train, per_train = train_one_epoch(model, train_loader, loss_fn, optimizer    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Validation</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>loss_valid, per_val = evaluate(model, valid_loader, loss_fn, perp)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_one_epoch</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">28</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>loss.backward()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>28 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>perplexity = perp(outputs.view(batch_size, seq_len, vocab_size), targets.view(batc    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>optimizer.step()                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>optimizer.zero_grad()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metric.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">298</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 295 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.full_state_update <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.full_state_update <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dist_sync_on  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 296 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_cache = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_full_state_update(*args, **kwargs)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 297 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 298 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_cache = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_reduce_state_update(*args, **kwargs)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 299 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 300 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_cache                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 301 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metric.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">367</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_forward_reduce_state_update</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 364 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._enable_grad = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># allow grads for batch computation</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 365 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 366 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calculate batch state and compute batch value</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 367 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.update(*args, **kwargs)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_val = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># reduce batch and global state</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">metric.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">457</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapped_func</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 454 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 455 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.set_grad_enabled(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._enable_grad):                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 456 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 457 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>update(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 458 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 459 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"Expected all tensors to be on\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(err):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 460 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/text/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">perplexity.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">82</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, preds: Tensor, target: Tensor) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Update state with predictions and targets.\"\"\"</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 82 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>total_log_probs, count = _perplexity_update(preds, target, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 83 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.total_log_probs += total_log_probs                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 84 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.count += count                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 85 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/functional/text/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">perplexity.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_perplexity_update</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mask = torch.ones_like(target, dtype=torch.bool)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>probs = probs[:, target].diagonal()[mask]                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>100 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>total_log_probs = -probs.log().sum()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>count = mask.sum()                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> total_log_probs, count                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(num_epochs):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# Train\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 \u001b[2m  \u001b[0mmodel, loss_train, per_train = train_one_epoch(model, train_loader, loss_fn, optimizer    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# Validation\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m  \u001b[0mloss_valid, per_val = evaluate(model, valid_loader, loss_fn, perp)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain_one_epoch\u001b[0m:\u001b[94m28\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│     \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│     \u001b[0mloss.backward()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m│     \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m28 \u001b[2m│     \u001b[0mperplexity = perp(outputs.view(batch_size, seq_len, vocab_size), targets.view(batc    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│     \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│     \u001b[0moptimizer.step()                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│     \u001b[0moptimizer.zero_grad()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/\u001b[0m\u001b[1;33mmetric.py\u001b[0m:\u001b[94m298\u001b[0m in \u001b[92mforward\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 295 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.full_state_update \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.full_state_update \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.dist_sync_on  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 296 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._forward_cache = \u001b[96mself\u001b[0m._forward_full_state_update(*args, **kwargs)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 297 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 298 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._forward_cache = \u001b[96mself\u001b[0m._forward_reduce_state_update(*args, **kwargs)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 299 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 300 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._forward_cache                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 301 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/\u001b[0m\u001b[1;33mmetric.py\u001b[0m:\u001b[94m367\u001b[0m in                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_forward_reduce_state_update\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._enable_grad = \u001b[94mTrue\u001b[0m  \u001b[2m# allow grads for batch computation\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 365 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 366 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# calculate batch state and compute batch value\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 367 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.update(*args, **kwargs)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 368 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_val = \u001b[96mself\u001b[0m.compute()                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# reduce batch and global state\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/\u001b[0m\u001b[1;33mmetric.py\u001b[0m:\u001b[94m457\u001b[0m in \u001b[92mwrapped_func\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 454 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._update_count += \u001b[94m1\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 455 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.set_grad_enabled(\u001b[96mself\u001b[0m._enable_grad):                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 456 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 457 \u001b[2m│   │   │   │   │   \u001b[0mupdate(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 458 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mRuntimeError\u001b[0m \u001b[94mas\u001b[0m err:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 459 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mExpected all tensors to be on\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m \u001b[96mstr\u001b[0m(err):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 460 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/text/\u001b[0m\u001b[1;33mperplexity.py\u001b[0m:\u001b[94m82\u001b[0m in \u001b[92mupdate\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mupdate\u001b[0m(\u001b[96mself\u001b[0m, preds: Tensor, target: Tensor) -> \u001b[94mNone\u001b[0m:                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Update state with predictions and targets.\"\"\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 82 \u001b[2m│   │   \u001b[0mtotal_log_probs, count = _perplexity_update(preds, target, \u001b[96mself\u001b[0m.ignore_index)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.total_log_probs += total_log_probs                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 84 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.count += count                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/hadi/anaconda3/lib/python3.10/site-packages/torchmetrics/functional/text/\u001b[0m\u001b[1;33mperplexity.py\u001b[0m:\u001b[94m100\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_perplexity_update\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   \u001b[0mmask = torch.ones_like(target, dtype=torch.bool)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0mprobs = probs[:, target].diagonal()[mask]                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m100 \u001b[2m│   \u001b[0mtotal_log_probs = -probs.log().sum()                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   \u001b[0mcount = mask.sum()                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m total_log_probs, count                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "max_lr_dec = 4\n",
    "lr_dec = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  # Train\n",
    "  model, loss_train, per_train = train_one_epoch(model, train_loader, loss_fn, optimizer, perp , epoch)\n",
    "  # Validation\n",
    "  loss_valid, per_val = evaluate(model, valid_loader, loss_fn, perp)\n",
    "\n",
    "  loss_train_hist.append(loss_train)\n",
    "  loss_valid_hist.append(loss_valid)\n",
    "\n",
    "  per_train_hist.append(per_train)\n",
    "  per_valid_hist.append(per_val)\n",
    "\n",
    "  lr_train_hist.append(lr)\n",
    "  \n",
    "  print(f'Valid: Loss = {loss_valid:.4} Perplexity= {per_val:.4}, LR = {lr}')\n",
    "  epoch_counter += 1\n",
    "  \n",
    "  if per_val < best_perplexity_valid:\n",
    "    lr_dec = 0\n",
    "    torch.save(model, f'model.pt')\n",
    "    best_perplexity_valid = per_val\n",
    "    print('Model Saved!')\n",
    "  else:\n",
    "    if lr_dec >= max_lr_dec :\n",
    "      print(\"LR_DEC==3 , Finished\")\n",
    "      break\n",
    "    lr_dec += 1\n",
    "    \n",
    "    del model\n",
    "    del perp\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    \n",
    "    model_path = 'model.pt'\n",
    "    model = torch.load(model_path,map_location=device)\n",
    "    lr /= 2\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    perp = Perplexity().to(device)\n",
    "  print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save as CSV\n",
    "import pandas as pd\n",
    "datas = {\n",
    "    'epoch': range(epoch_counter),\n",
    "    'loss_train': loss_train_hist,\n",
    "    'loss_validation': loss_valid_hist,\n",
    "    'perplexity_train': per_train_hist , \n",
    "    'perplexity_validation':per_valid_hist,\n",
    "    'learning_rate': lr_train_hist\n",
    "}\n",
    "df = pd.DataFrame(datas)\n",
    "df.to_csv(\"learningCurve.csv\" , index=False)\n",
    "\n",
    "fig, (ax1, ax2 , ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "ax1.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n",
    "ax1.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n",
    "ax1.set_title('Learning Curve')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(epoch_counter), per_train_hist, 'r-', label='Train')\n",
    "ax2.plot(range(epoch_counter), per_valid_hist, 'b-', label='Validation')\n",
    "ax2.set_title('Perplexity')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Perplexity')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(range(epoch_counter), lr_train_hist, 'r-', label='Rate')\n",
    "ax3.set_title('Learning Rate')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Rate')\n",
    "ax3.grid(True)\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Loss = 4.187 , Perplexity = 68.75\n",
      "Test: Loss = 4.076 , Perplexity = 63.34\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model.pt'\n",
    "model = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "perp = Perplexity().to(device)\n",
    "\n",
    "loss_valid , per_valid  = evaluate(model, valid_loader, loss_fn , perp )\n",
    "print(f\"Validation: Loss = {loss_valid:.4} , Perplexity = {per_valid:.4}\")\n",
    "\n",
    "loss_test , per_test  = evaluate(model, test_loader, loss_fn , perp)\n",
    "print(f\"Test: Loss = {loss_test:.4} , Perplexity = {per_test:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H_LSTM(\n",
       "  (embedding): Embedding(33264, 500)\n",
       "  (dropout_em): Dropout(p=0.1, inplace=False)\n",
       "  (rnn1): LSTM(500, 500, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (rnn2): LSTM(500, 500, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.25, inplace=False)\n",
       "  (rnn3): LSTM(500, 500, batch_first=True)\n",
       "  (dropout3): Dropout(p=0.25, inplace=False)\n",
       "  (fc): Linear(in_features=500, out_features=33264, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model_path = 'model.pt'\n",
    "model = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.309264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trainable_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think the movie represents the Tempest . = = = &lt; unk &gt; = = = The fourth pair of Venus on the top 32 faces are preserved without the other immense level . The low @ - @ neck technique reduces the high 240 @ - @ wing chains , measuring 25 @ , @ 000 metres ( 1 @ , @ 117 ft ) in length , with a jurisdiction in the 4th Scouts and lower feet over the back . The straight length , where the secondary pectoral is an intruder , light @ - @ side , and with\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt, max_seq_len, temperature, model ):\n",
    "\n",
    "    global device\n",
    "    global vocab_itos\n",
    "    global seq_len\n",
    "    global char2ind\n",
    "    \n",
    "    prompt_tokens = prompt.split(' ')\n",
    "    prompt_tokens = [vocab[token] for token in prompt_tokens]  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        current_token = torch.tensor(prompt_tokens).unsqueeze(0) \n",
    "        current_token = current_token.to(device)\n",
    "        generated_text = prompt  \n",
    "        for i in range(max_seq_len):\n",
    "            output = model(current_token)\n",
    "            probabilities = nn.functional.softmax(output[:, -1, :] / temperature, dim=-1)\n",
    "            next_word = \"<unk>\"\n",
    "            while next_word == \"<unk>\":\n",
    "                next_token_id = torch.multinomial(probabilities, 1).item()\n",
    "                next_word = vocab_itos[next_token_id]\n",
    "            \n",
    "            generated_text += \" \" + next_word\n",
    "\n",
    "            next_token_id = torch.tensor([[next_token_id]]).to(device)\n",
    "            if current_token.shape[1] < seq_len:\n",
    "                current_token = torch.cat( ( current_token  , next_token_id ), dim=1)\n",
    "            else:\n",
    "                current_token = torch.cat( ( current_token[:, 1:]  , next_token_id ), dim=1)\n",
    "            if next_word in [\"<eos>\"]:\n",
    "                break\n",
    "            del next_token_id\n",
    "    return generated_text\n",
    "\n",
    "prompt = \"i think the movie\"\n",
    "generated_text = generate(prompt, \n",
    "                          max_seq_len = 100, \n",
    "                          temperature = 0.9, \n",
    "                          model = model)\n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
